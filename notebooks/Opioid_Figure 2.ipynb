{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18899cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contour_visualization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcreate_mask_for_region\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontour_visualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#import shap\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# read heatmap plots\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#import Heatmap_plots as hmp\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contour_visualization'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from read_roi import read_roi_file\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import create_mask_for_region\n",
    "from datetime import datetime\n",
    "from contour_visualization import *\n",
    "\n",
    "#import shap\n",
    "# read heatmap plots\n",
    "#import Heatmap_plots as hmp\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tifffile as tiff\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9362011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure key\n",
    "figure_key = 'Figure2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8233a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "result_paths = r\"data/lsms/Opioid\"\n",
    "rootpath = r\"G:\\My Drive\\Opioid_whole_brain_manuscript\"\n",
    "metapath = os.path.join(rootpath,\"meta\")\n",
    "analysis_resultpath = os.path.join(rootpath,\"result\")\n",
    "analysis_root_figurepath = os.path.join(rootpath,\"figure\")\n",
    "analysis_figurepath = os.path.join(analysis_root_figurepath,figure_key)\n",
    "for path in [analysis_resultpath,analysis_root_figurepath,analysis_figurepath]:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "# load meta info of the files\n",
    "metadf = pd.read_csv(os.path.join(metapath,\"OP_meta.csv\"),index_col= False)\n",
    "# temporary drop of A7 due to missing data\n",
    "metadf = metadf[metadf.ID != 'A7'].reset_index(drop = True)\n",
    "# load brain atlas to register\n",
    "atlas_df = pd.read_csv(r\"data/atlas/atlas_info_KimRef_FPbasedLabel_v4.0_brain_with_size_with_curated_with_cleaned_acronyms.csv\",index_col = False)\n",
    "metacolumns = ['id','acronym','parent_acronym','parent_id','structure_order']\n",
    "contour_img = tifffile.imread(r\"data/atlas/Kim_ref_adult_FP-label_v2.9_contour_map.tif\")\n",
    "# retrieve list of files\n",
    "fnames =  [f for f in metadf.fname.values if 'DONE' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditions = metadf.Condition.unique()\n",
    "# Use only morphine related groups\n",
    "Conditions = ['Saline','Acute_Morphine','Chronic_Morphine','Withdrawal_Morphine','Chronic_Morphine_21','Withdrawal_Morphine_21',]\n",
    "print(Conditions)\n",
    "\n",
    "# subset the meta dataframe\n",
    "metadf = metadf[metadf.Condition.isin(Conditions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6018e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Set matplotlib parameters for white text on transparent background\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'none',  # Transparent figure background\n",
    "    'axes.facecolor': 'none',    # Transparent axes background\n",
    "    'axes.edgecolor': 'black',   # White axes edge color\n",
    "    'axes.labelcolor': 'black',  # White axis labels\n",
    "    'xtick.color': 'black',      # White tick labels\n",
    "    'ytick.color': 'black',      # White tick labels\n",
    "    'legend.facecolor': 'none',  # Transparent legend background\n",
    "    'legend.edgecolor': 'none',  # Transparent legend edgecolor\n",
    "    'text.color': 'black',       # White text color\n",
    "    'font.family':'Arial',\n",
    "    'pdf.fonttype':42,\n",
    "    'ps.fonttype':42,\n",
    "   \n",
    "})\n",
    "#important for text to be detected when importing saved figures into illustrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ffcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_resultpath,f'curated_acronym.pickle'), 'rb') as handle:\n",
    "    curated_acronyms = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(analysis_resultpath,f'ancestor_curated_acronym.pickle'), 'rb') as handle:\n",
    "    ancestor_curated_acronyms = pickle.load(handle,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7596e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saline', 'Acute_Morphine', 'Chronic_Morphine', 'Withdrawal_Morphine', 'Chronic_Morphine_21', 'Withdrawal_Morphine_21']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metadf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m Condition_color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcyan\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# subset the meta dataframe\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m metadf \u001b[38;5;241m=\u001b[39m \u001b[43mmetadf\u001b[49m[metadf\u001b[38;5;241m.\u001b[39mCondition\u001b[38;5;241m.\u001b[39misin(Conditions)]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# load and subset dataframes\u001b[39;00m\n\u001b[0;32m     17\u001b[0m pivot_heatmap_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(analysis_resultpath,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_pivoted_heatmap_df_with_normalized_density.csv\u001b[39m\u001b[38;5;124m'\u001b[39m),index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metadf' is not defined"
     ]
    }
   ],
   "source": [
    "default_depth = 4\n",
    "# set heatmap variables\n",
    "vmin= -5\n",
    "vmax = 10\n",
    "\n",
    "#Conditions = metadf.Condition.unique()\n",
    "# Use only morphine related groups\n",
    "Conditions = ['Saline','Acute_Morphine','Chronic_Morphine','Withdrawal_Morphine','Chronic_Morphine_21','Withdrawal_Morphine_21',]\n",
    "print(Conditions)\n",
    "#Condition_figure_name = ['Saline','Acute','Chronic 1 day','W.D. 1 day','Chronic 21 days','W.D. 21 days'] # changed this to betterones\n",
    "Condition_figure_name = ['Saline','Acute','Chronic','Early WD','Re-exposure','Late WD'] \n",
    "Condition_color = ['gray','lime','orange','cyan','blue','purple']\n",
    "# subset the meta dataframe\n",
    "metadf = metadf[metadf.Condition.isin(Conditions)]\n",
    "\n",
    "# load and subset dataframes\n",
    "pivot_heatmap_df = pd.read_csv(os.path.join(analysis_resultpath,'long_pivoted_heatmap_df_with_normalized_density.csv'),index_col = 0)\n",
    "pivot_heatmap_df = pivot_heatmap_df[metadf[metadf.Condition.isin(Conditions)]['ID'].values]\n",
    "merge_df  = pd.read_csv(os.path.join(analysis_resultpath,'Ex_639_Ch2_stitched_long_merge_Annotated_counts_with_leaf_with_density_with_normalized_density.csv'),index_col = 0)\n",
    "merge_df = merge_df[merge_df.Condition.isin(Conditions)]\n",
    "# Load the acronyms for plotting\n",
    "with open(os.path.join(analysis_resultpath,f'curated_acronym.pickle'), 'rb') as handle:\n",
    "    curated_acronyms = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(analysis_resultpath,f'ancestor_curated_acronym.pickle'), 'rb') as handle:\n",
    "    ancestor_curated_acronyms = pickle.load(handle,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdf0ec",
   "metadata": {},
   "source": [
    "remove HB and CBL from the list of ancestores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the ancestor curated acronyms so it matches the tree devisions\n",
    "unique_ancestor_curated_acronyms = ['Isocortex','OLF','HPF','CTXsp','STR','PAL','TH','HY','MB',]\n",
    "#unique_ancestor_curated_acronyms = ['Isocortex','OLF','HPF','CTXsp','STR','PAL','TH','HY','MB','HB','CBL']\n",
    "\n",
    "# get a list of idx for the ancestors\n",
    "ancestor_names = [atlas_df.loc[atlas_df.acronym == f,'name'].values[0] for f in unique_ancestor_curated_acronyms]\n",
    "ancestor_idxs = [atlas_df.loc[atlas_df.acronym == f,'id'].values[0] for f in unique_ancestor_curated_acronyms]\n",
    "'''\n",
    "curated_acronyms = []\n",
    "ancestor_curated_acronyms = []\n",
    "for idx,i in enumerate(ancestor_idxs):\n",
    "    create_mask_for_region.get_subregions(atlas_df,i,return_original = True)\n",
    "    tdf = create_mask_for_region.get_subregions(atlas_df,i,return_original = True)\n",
    "    curated_acronyms += list(tdf[tdf.Curated_list].acronym)\n",
    "    ancestor_curated_acronyms += [unique_ancestor_curated_acronyms[idx]]*tdf[tdf.Curated_list].shape[0]\n",
    "\n",
    "# save the new list of acronyms\n",
    "with open(os.path.join(analysis_resultpath,f'curated_acronym.pickle'), 'wb') as handle:\n",
    "    pickle.dump(curated_acronyms,handle,)\n",
    "\n",
    "with open(os.path.join(analysis_resultpath,f'ancestor_curated_acronym.pickle'), 'wb') as handle:\n",
    "    pickle.dump(ancestor_curated_acronyms,handle,)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d1dca",
   "metadata": {},
   "source": [
    "remove CBL and MB subtree from the atlas file and the merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove CBL and MB subtree from the data. These regions had bad registration quality and low interest\n",
    "remove_ancestor_ids = atlas_df[(atlas_df.acronym == 'HB') | (atlas_df.acronym == 'CBL')]['id'].values\n",
    "remove_df = pd.concat([create_mask_for_region.get_subregions(atlas_df,idx,return_original = True) for idx in remove_ancestor_ids],axis = 0)\n",
    "sub_atlas_df = atlas_df.set_index(['id']).drop(remove_df['id'].values)\n",
    "merge_df = merge_df[merge_df.acronym.isin(sub_atlas_df.acronym.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09adf4",
   "metadata": {},
   "source": [
    "set up the metacolumns to be compatible for GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load meta info of the files\n",
    "metadf['age'] = [(datetime.strptime( pday, '%m/%d/%Y') - datetime.strptime( dob, '%m/%d/%Y')).days for pday,dob in metadf.loc[:,['Date_Perfusion','DOB']].values]\n",
    "atlasmeta = merge_df.reset_index().loc[merge_df.reset_index().ID =='A1',['id','parent_id','acronym','name','parent_acronym']]\n",
    "\n",
    "#metaexog = metadf[['Condition','Sex','BW','age','Staining_Batch']]\n",
    "#metacolumns = ['Saline','Acute_Morphine','Chronic_Morphine','Sex_d','Batch_d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical values to dummy chategories dtypes\n",
    "sex_category = pd.CategoricalDtype(categories=['F', 'M'], ordered=False)\n",
    "condition_category = pd.CategoricalDtype(categories=Conditions, ordered=True)\n",
    "batch_category = pd.CategoricalDtype(categories=[1,2,3,4], ordered=False)\n",
    "\n",
    "merge_df['Sex']             = merge_df['Sex'].astype(sex_category)\n",
    "merge_df['Condition']       = merge_df['Condition'].astype(condition_category)\n",
    "\n",
    "merge_df['Staining_Batch']  = merge_df['Staining_Batch'].astype(batch_category)\n",
    "\n",
    "# create dummy cats\n",
    "condition_dummies           = pd.get_dummies(merge_df['Condition'])\n",
    "sex_dummies                 = pd.get_dummies(merge_df['Sex']).loc[:,['F']].rename(columns = {'F':'Sex_d'}) # female 1\n",
    "batch_dummies = pd.get_dummies(merge_df['Staining_Batch'])\n",
    "batch_dummies.columns = [f'Batch_{c}_d' for c in range(4)]\n",
    "\n",
    "merge_df                    = pd.concat([merge_df,condition_dummies,sex_dummies,batch_dummies],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76febff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flags for conditions\n",
    "#merge_df = pd.merge(merge_df,metadf[['ID','Acute_flag','Chronic_flag','Spontaneous_flag']],left_on = 'ID',right_on = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate effect size raw\n",
    "raw_effect_size_df = merge_df[['acronym','Condition','density']].groupby(['acronym','Condition',]).mean().reset_index()\\\n",
    ".pivot(columns = 'Condition',index = 'acronym',values = 'density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_df.loc[atlas_df.acronym.isin(curated_acronyms),['acronym','name']].to_csv(os.path.join(metapath,'clean_curated_acronyms.csv'),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103f27e",
   "metadata": {},
   "source": [
    "Prepare heatmaps into a dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an annotated atlas file\n",
    "atlas_img = tifffile.imread(r\"data/atlas/Kim_ref_adult_FP-label_v4.0.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d45d6",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b1981",
   "metadata": {},
   "source": [
    "## Figure 2C, D and E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35247254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea67a3",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d99518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set conditions to compare\n",
    "#sub_conditions  = ['Saline','Acute_Morphine']\n",
    "sub_conditions  = ['Saline','Acute_Morphine','Chronic_Morphine','Withdrawal_Morphine','Chronic_Morphine_21','Withdrawal_Morphine_21',]\n",
    "sub_IDs         = metadf[metadf.Condition.isin(sub_conditions)].ID.values\n",
    "sub_merge_df    = merge_df[merge_df.Condition.isin(sub_conditions)]\n",
    "#sub_pivot_df    = pivot_heatmap_df[sub_IDs]\n",
    "sub_pivot_df    = merge_df.pivot(columns = 'ID',index= 'acronym',values = 'density')[sub_IDs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddaa047",
   "metadata": {},
   "source": [
    "### GLM test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd01865",
   "metadata": {},
   "source": [
    "Conduct a GLM test with a likelihood ratio test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dca640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the metacolumns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# First test if there is a difference in the average decay length between the 5 types.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "def chi2_model_comparison(model1,model2):\n",
    "    # Get the log-likelihoods of the models\n",
    "    ll_null = model1.llf  # log-likelihood of the full model\n",
    "    ll_restricted = model2.llf  # log-likelihood of the restricted model\n",
    "\n",
    "    # Calculate the difference in log-likelihoods\n",
    "    ll_diff = -2 * (ll_restricted - ll_null)\n",
    "\n",
    "    # Degrees of freedom is the difference in the number of parameters\n",
    "    df = model1.df_model - model2.df_model\n",
    "\n",
    "    # Compute the p-value\n",
    "    p_value = chi2.sf(ll_diff, df)\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a constant\n",
    "sub_merge_df['constant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67e7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the metacolumns to use in the model\n",
    "metacolumns = list(sub_conditions[1:]) + ['constant'] + ['Sex_d','BW','Age',]  # drop saline\n",
    "# Select only continuous variables for scaling\n",
    "continuous_vars = ['BW', 'Age']  # Modify as needed\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Predefine the link function\n",
    "family = sm.families.NegativeBinomial()\n",
    "\n",
    "for idx,acronym in enumerate(sub_merge_df.acronym.unique()):\n",
    "    # don't run test if not enough subjects which seems to happen\n",
    "    exog = sub_merge_df.loc[(sub_merge_df.acronym == acronym),metacolumns]\n",
    "    exog[continuous_vars] = scaler.fit_transform(exog[continuous_vars])\n",
    "    endog = sub_merge_df.loc[(sub_merge_df.acronym == acronym),'density']\n",
    "    if idx == 0:\n",
    "        sns.heatmap(np.array(exog.astype('float')))\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        # run multiple GLM fits and comparison while dropping one of the variables\n",
    "\n",
    "        glmfit = sm.GLM(endog, np.asarray(exog.astype('float64')),family=family,).fit()\n",
    "        tglmfit = sm.GLM(endog, exog.astype('float64').drop(columns = sub_conditions[1:]),family=family,).fit() # Drop the conditions\n",
    "\n",
    "        pvalue = chi2_model_comparison(glmfit,tglmfit) # calculate the pvalue from the chi2 likelihood test of the two models\n",
    "        tdf = pd.DataFrame([pvalue],columns = ['Condition'])\n",
    "        tdf['acronym'] = acronym\n",
    "    except:\n",
    "        # if doesn't run, save a nan\n",
    "        # tdf = pd.DataFrame({'F':np.nan,'PR(>F)':np.nan,'acronym':acronym},index = [0])\n",
    "        print(acronym)\n",
    "        #tdf = pd.DataFrame(np.nan * np.zeros((1,len(metacolumns))),columns = metacolumns) # put pvalue of 1 with empty\n",
    "        tdf = pd.DataFrame([np.nan],columns = ['Condition']) # put pvalue of 1 with empty\n",
    "        tdf['acronym'] = acronym\n",
    "        #print(acronym, \" did not have enough subjects\")\n",
    "\n",
    "    if idx == 0:\n",
    "        glm_stat_df = tdf\n",
    "    else:\n",
    "        glm_stat_df = pd.concat([glm_stat_df,tdf],axis=  0,).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the glm stat data frame\n",
    "glm_stat_df = pd.merge(create_mask_for_region.get_subregions(atlasmeta, 8, return_original=True),glm_stat_df,left_on = 'acronym',right_on = 'acronym').\\\n",
    "    rename(columns = {'name':'Name','Condition':'pvalue'})\n",
    "glm_stat_df.to_csv(os.path.join(analysis_resultpath,f'{figure_key}_{pannel_key}_glm_stat_df_no_batch.csv'),index = False)\n",
    "print(f'{figure_key}_{pannel_key}_glm_stat_df_no_batch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TreeBH\n",
    "# you can run it with python too\n",
    "'''input_csv = r\"data/results/Figure2_C_glm_stat_df_no_batch.csv\"\n",
    "output_dir = r\"data/results_test\"\n",
    "TreeBH.run_tree_fdr_pipeline(\n",
    "    input_csv,\n",
    "    output_dir,\n",
    "    pval_col=\"pvalue\",\n",
    "    save_key=\"Figure2_C_glm_stat_df_no_batch\",\n",
    "    q_thresh=0.001,\n",
    "    plot_html=True  # Set to False to skip HTML plot\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044acfb1",
   "metadata": {},
   "source": [
    "### Run TreeBH to correct for multiple comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb407396",
   "metadata": {},
   "source": [
    "Run TreeFDR for the acute vs. saline GLM test results with a p=0.001 threshold. This will happen on a separate R script (Opioid_Figure 2_TreeBH.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results from the treeFDR f\n",
    "TreeFDRF_df = pd.read_csv(os.path.join(analysis_resultpath,\\\n",
    "    f'TreeFDRF_pvalue_{figure_key}_{pannel_key}_glm_stat_df_no_batch.csv'),index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'TreeFDRF_pvalue_{figure_key}_{pannel_key}_glm_stat_df_no_batch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b851d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rejected acronyms\n",
    "rejected_acronyms = TreeFDRF_df[(TreeFDRF_df.acronym.isin(curated_acronyms)) & (TreeFDRF_df.rejected == True)].acronym.values \n",
    "print(len(rejected_acronyms),\" rejected acronyms\")\n",
    "print(rejected_acronyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66173578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25146bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of leaf nodes that are rejected per major subtree\n",
    "unique_ancestor_curated_acronyms = np.unique(ancestor_curated_acronyms)\n",
    "\n",
    "for ancestor_acronym in unique_ancestor_curated_acronyms:\n",
    "    # get the acnstor_id\n",
    "    ancestor_id = atlas_df[atlas_df.acronym == ancestor_acronym].id.values[0]\n",
    "    # get the subregions of the ancestor acronym\n",
    "    subregions_df = create_mask_for_region.get_subregions(atlas_df,ancestor_id,return_original = True)\n",
    "    # get the leafnodes\n",
    "    leafnodes = np.setdiff1d(subregions_df['acronym'],subregions_df['parent_acronym'])\n",
    "    # get the rejected acronyms in this subtree\n",
    "    rejected_leafnodes = TreeFDRF_df[(TreeFDRF_df.acronym.isin(leafnodes))&(TreeFDRF_df.rejected == True)].acronym.values\n",
    "\n",
    "    # calculate the proportion of rejected acronyms in this subtree\n",
    "    proportion_rejected = len(rejected_leafnodes) / len(leafnodes)\n",
    "    print(f\"{ancestor_acronym}: {len(rejected_leafnodes)} / {len(leafnodes)} rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f282729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of rejected regions from the TreeFDR result\n",
    "sub_rejected_acronyms = TreeFDRF_df[(TreeFDRF_df.rejected == True) & (TreeFDRF_df.acronym.isin(curated_acronyms))].acronym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702c229",
   "metadata": {},
   "source": [
    "### Plot for Figure C and D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8a484",
   "metadata": {},
   "source": [
    "Run a sunburst plot app. Plot the sunburst plot along with the betacoef result of acute morphine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pannel\n",
    "pannel_key = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import active_sunburst as sunburst\n",
    "# reload function sunburst\n",
    "import importlib\n",
    "importlib.reload(sunburst)\n",
    "\n",
    "betacoef = np.load(os.path.join(r\"data/opioid_cfos/result\",f'Acute_Morphine_betas.npy'))\n",
    "tTreeFDRF_df = pd.merge(TreeFDRF_df[['acronym','rejected','p.val']],atlas_df,left_on = 'acronym',right_on = 'acronym',how = 'inner')\n",
    "sunburst.run_app(tTreeFDRF_df, betacoef, atlas_img, os.path.join(analysis_figurepath,f'{figure_key}_sunburst'),\n",
    "data_variable = 'rejected',colormap =  plt.cm.coolwarm,cmin = -20,cmax = 20,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adde552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "456d5432",
   "metadata": {},
   "source": [
    "## Figure F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "fig,axs = plt.subplots(1,1,figsize = (5,2))\n",
    "tdata = merge_df.loc[merge_df.acronym.isin(ancestor_curated_acronyms),:]\n",
    "\n",
    "sns.stripplot(data = tdata,hue = 'Condition',y = 'density',x = 'acronym',dodge = True,\\\n",
    "        hue_order = Conditions,ax = axs,palette = Condition_color,alpha = 0.15,order = unique_ancestor_curated_acronyms)\n",
    "sns.pointplot(data = tdata,hue = 'Condition',y = 'density',x = 'acronym',dodge = .8-.8/len(np.unique(ancestor_curated_acronyms)),\\\n",
    "        hue_order = Conditions,ax = axs,palette = Condition_color,order = unique_ancestor_curated_acronyms,\n",
    "markers=\"o\", markersize=4, linestyle=\"none\",linewidth = 0.5)        \n",
    "sns.despine()\n",
    "axs.set_ylabel('c-Fos+ cell density\\n(cells/mm3)')\n",
    "# remove the figure legend\n",
    "axs.get_legend().remove()\n",
    "axs.set_xticklabels(unique_ancestor_curated_acronyms,rotation = -45)\n",
    "\n",
    "fig.savefig(os.path.join(analysis_figurepath,f'{figure_key}{pannel_key}.png'),bbox_inches = 'tight',dpi = 216)\n",
    "fig.savefig(os.path.join(analysis_figurepath,f'{figure_key}{pannel_key}.pdf'),bbox_inches = 'tight',dpi = 216)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20429709",
   "metadata": {},
   "source": [
    "## Figure G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806be263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convert the rejected column to -1, 0, 1 (Not-rejected, Not-tested, Rejected)\n",
    "# Merge the results from multiple formats\n",
    "a = TreeFDRF_df.loc[TreeFDRF_df.acronym.isin(curated_acronyms),['acronym','rejected']].astype('str').replace('nan',0).replace('False',-1).replace('True',1).rename(columns = {'rejected':'TreeBH_F'})\n",
    "heatmapdf = pd.concat([a.set_index('acronym')],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# set parameters\n",
    "vmin = 0\n",
    "vmax = 2000\n",
    "\n",
    "# Custom colormap for the first subplot\n",
    "cmap = ListedColormap(['white', 'gray', 'magenta'])  # Colors for -1, 0, 1\n",
    "bounds = [-1.5, -0.5, 0.5, 1.5]  # Boundaries for the values\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create the merged figure\n",
    "total_rows = len(sub_conditions) + 1  # Adding one row for the second figure\n",
    "\n",
    "fig, axs = plt.subplots(total_rows, 1, figsize=(5, len(sub_conditions)*0.4 + 1), sharex=True, \\\n",
    "    gridspec_kw={\"height_ratios\": [0.25] + [1] * len(sub_conditions)})\n",
    "# Plot the first subplot (top row)\n",
    "theatmapdf = heatmapdf.loc[curated_acronyms, ['TreeBH_F']]\n",
    "subset_ancestor_curated_acronyms = [ancestor_curated_acronyms[idx] for idx, f in enumerate(curated_acronyms) if f in theatmapdf.index]\n",
    "\n",
    "__, indexes = np.unique(subset_ancestor_curated_acronyms, return_index=True)\n",
    "ytick_labels = [subset_ancestor_curated_acronyms[index] for index in sorted(indexes)]\n",
    "counts = [len(np.where(np.array(subset_ancestor_curated_acronyms) == ylabel)[0]) for ylabel in ytick_labels]\n",
    "\n",
    "borders = [0] + list(np.cumsum(counts))\n",
    "x = np.array(borders)\n",
    "yticks = (x[1:] + x[:-1]) / 2\n",
    "\n",
    "sns.heatmap(data=theatmapdf.T, cbar=False, ax=axs[0], cmap=cmap, norm=norm)  # Applied custom colormap and norm\n",
    "axs[0].set_xticks(yticks)\n",
    "axs[0].set_xticklabels(ytick_labels, rotation=0)\n",
    "axs[0].set_xlabel('')\n",
    "[axs[0].axvline(border, color='white', lw=1, ls=':') for border in borders[1:-1]]\n",
    "axs[0].set_yticks([0.5])\n",
    "axs[0].set_yticklabels(['Discoveries'], rotation=0)\n",
    "\n",
    "# Plot the remaining subplots\n",
    "for idx, condition in enumerate(sub_conditions):\n",
    "    subjects = metadf[(metadf.Condition == condition) & (metadf.fname)].ID.values\n",
    "    if idx == len(sub_conditions) - 1:\n",
    "        cbar_ax = fig.add_axes([axs[idx + 1].get_position().x1 + 0.01, axs[idx + 1].get_position().y0 + 0.2, 0.02, 0.5])  # Adjusted colorbar width\n",
    "        sns.heatmap(data=sub_pivot_df.loc[curated_acronyms, subjects].T, cbar_ax=cbar_ax, ax=axs[idx + 1],\\\n",
    "             vmin=vmin, vmax=vmax)\n",
    "        cbar_ax.set_ylabel('c-Fos+ cell density\\n(cells/mm3)', rotation=270, labelpad=10, fontsize=10)\n",
    "    else:\n",
    "        sns.heatmap(data=sub_pivot_df.loc[curated_acronyms, subjects].T, cbar=False, ax=axs[idx + 1], vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    axs[idx + 1].set_xticks(yticks)\n",
    "    axs[idx + 1].set_xticklabels(ytick_labels, rotation=-45)\n",
    "    axs[idx + 1].set_xlabel('')\n",
    "    [axs[idx + 1].axvline(border, color='yellow', lw=1.5, ls=':') for border in borders[1:-1]]\n",
    "    axs[idx + 1].set_yticks([len(subjects) // 2 + 0.5])\n",
    "    axs[idx + 1].set_ylabel('')\n",
    "    axs[idx + 1].set_yticklabels([Condition_figure_name[np.where(np.array(Conditions) == sub_conditions[idx])[0][0]]],rotation = 0)  \n",
    "    #axs[idx + 1].set_yticklabels([Condition_figure_name[[np.where(Conditions == f)[0][0] for f in sub_conditions][idx]]], rotation=0)\n",
    "\n",
    "# Save the merged figure\n",
    "fig.savefig(os.path.join(analysis_figurepath, f'{figure_key}{pannel_key}.png'), bbox_inches='tight', dpi=216)\n",
    "fig.savefig(os.path.join(analysis_figurepath, f'{figure_key}{pannel_key}.pdf'), bbox_inches='tight', dpi=216)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8418a6",
   "metadata": {},
   "source": [
    "## Figure H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script conducts two analyses on neural activity data:\n",
    "\n",
    "1. Correlation Analysis:\n",
    "   - Computes the pairwise Pearson correlation between the mean neural activity vectors (across brain regions)\n",
    "     for each drug condition group.\n",
    "   - Prints and plots the correlation matrix, and reports which condition pair has the highest correlation.\n",
    "\n",
    "2. Classification Analysis:\n",
    "   - Builds one‐vs‐rest logistic regression classifiers (using cross-validation) to predict the condition from neural activity.\n",
    "   - Reports the cross-validated accuracy for each condition.\n",
    "\n",
    "Data Assumptions:\n",
    " - pivot_heatmap_df: A DataFrame where rows are brain regions and columns are subject IDs.\n",
    " - metadf: A DataFrame with columns \"ID\" (subject ID) and \"Condition\" (drug condition information).\n",
    "\n",
    "Make sure that the subject IDs in pivot_heatmap_df’s columns exactly match the IDs in metadf.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def correlation_analysis(data, condition_labels):\n",
    "    \"\"\"\n",
    "    Computes pairwise Pearson correlation coefficients between the mean neural activity vectors\n",
    "    (across brain regions) for each condition.\n",
    "    \n",
    "    Parameters:\n",
    "        data: numpy array of shape (n_regions, n_subjects)\n",
    "        condition_labels: numpy array of shape (n_subjects,) with condition labels\n",
    "        \n",
    "    Returns:\n",
    "        corr_matrix: (n_conditions x n_conditions) array of Pearson correlations.\n",
    "        conditions_list: list of unique condition labels.\n",
    "        best_pair: tuple (cond1, cond2) for the pair with the highest correlation.\n",
    "        max_corr: highest correlation value.\n",
    "    \"\"\"\n",
    "    unique_conditions = np.unique(condition_labels)\n",
    "    mean_vectors = {}\n",
    "    for cond in unique_conditions:\n",
    "        # Find indices for subjects in this condition and compute mean activity across those subjects.\n",
    "        idx = np.where(condition_labels == cond)[0]\n",
    "        mean_vectors[cond] = np.mean(data[:, idx], axis=1)\n",
    "        \n",
    "    n = len(unique_conditions)\n",
    "    corr_matrix = np.zeros((n, n))\n",
    "    conditions_list = list(unique_conditions)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            vec_i = mean_vectors[conditions_list[i]]\n",
    "            vec_j = mean_vectors[conditions_list[j]]\n",
    "            corr = np.corrcoef(vec_i, vec_j)[0, 1]\n",
    "            corr_matrix[i, j] = corr\n",
    "\n",
    "    # Find the off-diagonal pair with the highest correlation.\n",
    "    max_corr = -np.inf\n",
    "    best_pair = (None, None)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if corr_matrix[i, j] > max_corr:\n",
    "                max_corr = corr_matrix[i, j]\n",
    "                best_pair = (conditions_list[i], conditions_list[j])\n",
    "                \n",
    "    return corr_matrix, conditions_list, best_pair, max_corr\n",
    "\n",
    "def plot_correlation_matrix(corr_matrix, conditions_list,outputpath = None,figsize = (5,4)):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the correlation matrix.\n",
    "    \"\"\"\n",
    "    fig,axs = plt.subplots(1,1,figsize=figsize)\n",
    "    sns.heatmap(corr_matrix, annot=True, xticklabels=conditions_list,\n",
    "                yticklabels=conditions_list, cmap=\"coolwarm\", vmin=-1, vmax=1,ax = axs)\n",
    "    axs.set_title(\"Correlation Matrix of Mean Neural Activity by Condition\")\n",
    "    axs.set_xlabel(\"Condition\")\n",
    "    axs.set_ylabel(\"Condition\")\n",
    "    if outputpath:\n",
    "        fig.savefig(outputpath,dpi = 216,bbox_inches= 'tight')\n",
    "        fig.savefig(outputpath.replace('.png','.pdf'),dpi = 216,bbox_inches= 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "def classification_analysis(X_data, condition_labels, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs one-vs-rest classification (using logistic regression) for each condition.\n",
    "    \n",
    "    Parameters:\n",
    "        X_data: numpy array of shape (n_subjects, n_regions)\n",
    "        condition_labels: numpy array of shape (n_subjects,)\n",
    "        n_splits: number of folds for cross-validation\n",
    "        \n",
    "    Returns:\n",
    "        clf_results: dictionary mapping each condition to its mean cross-validated accuracy.\n",
    "    \"\"\"\n",
    "    unique_conditions = np.unique(condition_labels)\n",
    "    clf_results = {}\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for cond in unique_conditions:\n",
    "        # Create binary labels: 1 if the subject is in the current condition, 0 otherwise.\n",
    "        y_binary = (condition_labels == cond).astype(int)\n",
    "        clf = LogisticRegression(solver='liblinear', random_state=42)\n",
    "        scores = cross_val_score(clf, X_data, y_binary, cv=skf, scoring='accuracy')\n",
    "        mean_score = np.mean(scores)\n",
    "        clf_results[cond] = mean_score\n",
    "        print(f\"Condition {cond}: Mean CV Accuracy = {mean_score:.3f}\")\n",
    "    \n",
    "    return clf_results\n",
    "\n",
    "def main(pivot_heatmap_df,metadf):\n",
    "    # ----------------------------\n",
    "    # Load the dataframes.\n",
    "    # Adjust the file paths or replace with your loading mechanism as needed.\n",
    "    # ----------------------------\n",
    "\n",
    "    \n",
    "    # pivot_heatmap_df: rows are brain regions, columns are subject IDs.\n",
    "    # Convert the data to a numpy array.\n",
    "    data = pivot_heatmap_df.values  # Shape: (n_regions, n_subjects)\n",
    "    \n",
    "    # Extract condition labels in the same order as the subject IDs (columns of pivot_heatmap_df).\n",
    "    # This assumes that metadf['ID'] exactly matches the subject IDs in pivot_heatmap_df.columns.\n",
    "    condition_labels = metadf.set_index('ID').loc[pivot_heatmap_df.columns, 'Condition'].values\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Part 1: Correlation Analysis\n",
    "    # ----------------------------\n",
    "    corr_matrix, conditions_list, best_pair, max_corr = correlation_analysis(data, condition_labels)\n",
    "    print(\"Correlation Matrix (Mean Neural Activity by Condition):\")\n",
    "    for i, cond in enumerate(conditions_list):\n",
    "        print(f\"Condition {cond}: {corr_matrix[i]}\")\n",
    "    print(f\"\\nStrongest correlation is between Condition {best_pair[0]} and Condition {best_pair[1]} with r = {max_corr:.3f}\")\n",
    "    \n",
    "    plot_correlation_matrix(corr_matrix, conditions_list)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Part 2: Classification Analysis\n",
    "    # ----------------------------\n",
    "    # Transpose the data to have subjects as rows and brain regions as features.\n",
    "    X_data = data.T  # Shape: (n_subjects, n_regions)\n",
    "    print(\"\\nPerforming one-vs-rest classification for each condition:\")\n",
    "    clf_results = classification_analysis(X_data, condition_labels, n_splits=5)\n",
    "    return corr_matrix, conditions_list,clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e15e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix, conditions_list,clf_results = main(pivot_heatmap_df.loc[curated_acronyms,metadf[metadf.Condition != 'Saline'].ID]\\\n",
    "    ,metadf[metadf.Condition !='Saline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath = os.path.join(analysis_figurepath,f'{figure_key}{pannel_key}.png')\n",
    "fig,axs = plt.subplots(1,1,figsize=(5,4))\n",
    "sns.heatmap(corr_matrix, annot=True, xticklabels=conditions_list,\n",
    "            yticklabels=conditions_list, cmap=\"coolwarm\", vmin=0, vmax=1,ax = axs)\n",
    "#axs.set_title(\"Correlation Matrix of Mean Neural Activity by Condition\")\n",
    "axs.set_xlabel(\"Condition\")\n",
    "axs.set_ylabel(\"Condition\")\n",
    "axs.set_xticklabels([Condition_figure_name[np.where(np.array(Conditions) == f)[0][0]] for f in conditions_list],rotation = -45)\n",
    "axs.set_yticklabels([Condition_figure_name[np.where(np.array(Conditions) == f)[0][0]] for f in conditions_list],rotation = 0)\n",
    "\n",
    "fig.savefig(outputpath,dpi = 216,bbox_inches= 'tight')\n",
    "fig.savefig(outputpath.replace('.png','.pdf'),dpi = 216,bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e6f37",
   "metadata": {},
   "source": [
    "## Figure I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fedd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "def run_bootstrap_auc(X, y, n_iterations=1000, random_seed=42):\n",
    "    \"\"\"\n",
    "    Perform one-vs-rest classification for each unique class in y,\n",
    "    using bootstrap iterations and random shuffling for null distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray, shape (n_samples, n_features), standardized input data\n",
    "    - y: np.ndarray, shape (n_samples,), condition labels\n",
    "    - n_iterations: int, number of bootstrap iterations\n",
    "    - random_seed: int, base seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - results: dict, contains AUC distributions for each condition\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    unique_conditions = np.unique(y)\n",
    "    results = {}\n",
    "\n",
    "    for condition in unique_conditions:\n",
    "        print(f\"Running bootstrap for: {condition}\")\n",
    "        # Create binary labels: 1 for current condition, 0 for rest\n",
    "        y_bin = (y == condition).astype(int)\n",
    "\n",
    "        true_scores = []\n",
    "        random_scores = []\n",
    "\n",
    "        for i in tqdm(range(n_iterations)):\n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y_bin, test_size=0.3, stratify=y_bin, random_state=i\n",
    "                )\n",
    "                # Skip if not both classes present\n",
    "                if len(np.unique(y_test)) < 2:\n",
    "                    continue\n",
    "\n",
    "                rf = RandomForestClassifier(n_estimators=100, random_state=i)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict_proba(X_test)[:, 1]\n",
    "                true_auc = roc_auc_score(y_test, y_pred)\n",
    "                true_scores.append(true_auc)\n",
    "\n",
    "                # Randomized label baseline\n",
    "                y_train_shuffled = np.random.permutation(y_train)\n",
    "                rf.fit(X_train, y_train_shuffled)\n",
    "                y_pred_rand = rf.predict_proba(X_test)[:, 1]\n",
    "                rand_auc = roc_auc_score(y_test, y_pred_rand)\n",
    "                random_scores.append(rand_auc)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping iteration {i} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        results[condition] = {\n",
    "            \"true_scores\": np.array(true_scores),\n",
    "            \"random_scores\": np.array(random_scores),\n",
    "            \"p_value\": ttest_ind(true_scores, random_scores, equal_var=False)[1]\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd741e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# use the normalized density dataframe as input\n",
    "X = pivot_heatmap_df.loc[curated_acronyms,metadf[metadf.Condition != 'Saline']['ID'].values].values.T\n",
    "# Standardize features (important for many classifiers)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = metadf[metadf.Condition!= 'Saline']['Condition'].values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "# Ensure input is standardized (already done above)\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "results = run_bootstrap_auc(X, y, n_iterations=1000)\n",
    "\n",
    "# Save for later\n",
    "import pickle\n",
    "with open(\"bootstrap_auc_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b75f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize = (1.5,2.5))\n",
    "for cidx,c in enumerate(Conditions):\n",
    "    if c == 'Saline':\n",
    "        continue\n",
    "\n",
    "    sns.ecdfplot(results[c]['true_scores'], label=np.array(Condition_figure_name)[np.where(np.array(Conditions) == c)[0]][0],\\\n",
    "        color=Condition_color[cidx],ax= axs)\n",
    "    sns.ecdfplot(results[c]['random_scores'], label='Shuffle',color='grey',alpha = 0.5,ax = axs)\n",
    "axs.set_xlabel('AUC score')\n",
    "fig.savefig(os.path.join(analysis_figurepath,f'{figure_key}{pannel_key}.png'),bbox_inches = 'tight',dpi = 216)\n",
    "fig.savefig(os.path.join(analysis_figurepath,f'{figure_key}{pannel_key}.pdf'),bbox_inches = 'tight',dpi = 216)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aacec5",
   "metadata": {},
   "source": [
    "# Figure 2-supplemental figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure key\n",
    "figure_key = 'Figure2-supplemental figure 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "result_paths = r\"data/lsms/Opioid\"\n",
    "rootpath = r\"G:\\My Drive\\Opioid_whole_brain_manuscript\"\n",
    "metapath = os.path.join(rootpath,\"meta\")\n",
    "analysis_resultpath = os.path.join(rootpath,\"result\")\n",
    "analysis_root_figurepath = os.path.join(rootpath,\"figure\")\n",
    "analysis_figurepath = os.path.join(analysis_root_figurepath,figure_key)\n",
    "for path in [analysis_resultpath,analysis_root_figurepath,analysis_figurepath]:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d0e35",
   "metadata": {},
   "source": [
    "## Figure A to H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf2e4b",
   "metadata": {},
   "source": [
    "Use the TreeBH results from Figure 2 and conduct comparisons with different multiple comparison approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a9ef8",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0747c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the treebh stats\n",
    "#opioid_treebh_df = pd.read_csv(os.path.join(datapath, \"TreeFDRF_p_val_opioid.csv\"))\n",
    "opioid_stat_df = pd.read_csv(os.path.join(analysis_resultpath,\\\n",
    "    f'Figure2_C_glm_stat_df_no_batch.csv'),index_col = False)\n",
    "\n",
    "opioid_treebh_df = pd.read_csv(os.path.join(analysis_resultpath,\\\n",
    "    f'TreeFDRF_pvalue_Figure2_C_glm_stat_df_no_batch.csv'),index_col = False)\n",
    "# FDR is set to 0.01 for the TreeBH \n",
    "FDR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a flat bh correction on the opioid_df\n",
    "import statsmodels.stats.multitest as multitests\n",
    "\n",
    "# create a dataframe to store all the pvlaues corrected by different algorithms\n",
    "# tree bh\n",
    "opioid_bh_comparison_df = opioid_treebh_df.copy()\n",
    "opioid_bh_comparison_df['Fishers_p_val'] = opioid_treebh_df['p.val'].astype(float)\n",
    "opioid_bh_comparison_df['TreeBH_rejected'] = opioid_treebh_df['rejected']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc44b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BH with Fisher's collected pvalues\n",
    "fishers_pvals = opioid_treebh_df.set_index('acronym').loc[curated_acronyms,'p.val']\n",
    "multiple_testing_results = multitests.multipletests(fishers_pvals, alpha=FDR, method='fdr_bh')\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.set_index('acronym')\n",
    "opioid_bh_comparison_df.loc[curated_acronyms,'flatbh_Fishers_rejected'] = multiple_testing_results[0]\n",
    "opioid_bh_comparison_df.loc[curated_acronyms,'flatbh_Fishers_p_val'] = multiple_testing_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BH with pvalues calculated by averaged data\n",
    "nonfishers_pvals = opioid_stat_df.set_index('acronym').loc[curated_acronyms,'pvalue']\n",
    "multiple_testing_results = multitests.multipletests(nonfishers_pvals, alpha=FDR, method='fdr_bh')\n",
    "opioid_bh_comparison_df.loc[curated_acronyms,'flatbh_non-Fishers_rejected'] = multiple_testing_results[0]\n",
    "opioid_bh_comparison_df.loc[curated_acronyms,'flatbh_non-Fishers_p_val'] = multiple_testing_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f294fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the opioid_bh_comparison_df to csv file\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.reset_index()\n",
    "opioid_bh_comparison_df.to_csv(os.path.join(analysis_resultpath, f\"{figure_key}_opioid_bh_comparison_df.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeFDRF_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13b8fd",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "opioid_bh_comparison_df = pd.read_csv(os.path.join(analysis_resultpath, f\"{figure_key}_opioid_bh_comparison_df.csv\"), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721309dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_keys = ['flatbh_non-Fishers','flatbh_Fishers','TreeBH',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6609409",
   "metadata": {},
   "source": [
    "### Figure B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rejected results as a barplot, without a error bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for plotting\n",
    "rejected_counts = {\n",
    "    key: np.sum(opioid_bh_comparison_df.loc[opioid_bh_comparison_df.acronym.isin(curated_acronyms),f'{key}_rejected'] == True)/len(curated_acronyms)\n",
    "    for key in comparison_keys\n",
    "}\n",
    "\n",
    "# Create barplot\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.bar(comparison_keys, \\\n",
    "    [rejected_counts[f] for f in comparison_keys],color='skyblue')\n",
    "plt.xlabel('Correction Method')\n",
    "plt.ylabel(f'Proportion of discoveries\\n(total {len(curated_acronyms)} regions)')\n",
    "plt.xticks([0,1,2],[\"FlatBH\\n(non-Fisher's)\",\"FlatBH\\n(Fisher's)\",\"TreeBH\",], rotation=0)\n",
    "sns.despine()\n",
    "plt.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e7fa9",
   "metadata": {},
   "source": [
    "### Figure C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db02e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "\n",
    "# Prepare data for Venn diagram\n",
    "treebh_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['TreeBH_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "flatbh_fishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "flatbh_nonfishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_non-Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "\n",
    "# Create Venn diagram\n",
    "fig,axs = plt.subplots(figsize=(4,3))\n",
    "venn3([treebh_rejected, flatbh_fishers_rejected, flatbh_nonfishers_rejected],\n",
    "      ('TreeBH', 'FlatBH (Fisher)', 'FlatBH (Non-Fisher)'),ax = axs)\n",
    "axs.set_title('Overlap of Rejected Decisions Across Methods')\n",
    "fig.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"), dpi=300, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30eb97c",
   "metadata": {},
   "source": [
    "### preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16789816",
   "metadata": {},
   "source": [
    "Deinfe Group A,B,C as A: True in all 3 methods, B: True in TreeBH and Fisher FlatBH but not in non Fisher, C: True only in Fisher FlatBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics for sets of brain regions in the brain_regions_category\n",
    "# Prepare data for Venn diagram\n",
    "treebh_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['TreeBH_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "flatbh_fishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "flatbh_nonfishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_non-Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the common in treebh_rejected, flatbh_fishers_rejected, flatbh_nonfishers_rejected\n",
    "groupA = treebh_rejected & flatbh_fishers_rejected & flatbh_nonfishers_rejected\n",
    "\n",
    "# find the common in treebh_rejected and flatbh_fishers_rejected but not in flatbh_nonfishers_rejected\n",
    "groupB = (treebh_rejected & flatbh_fishers_rejected) - flatbh_nonfishers_rejected\n",
    "\n",
    "# find only in flatbh_fishers_rejected but not in treebh_rejected and not in flatbh_nonfishers_rejected\n",
    "groupC = (flatbh_fishers_rejected - treebh_rejected) - flatbh_nonfishers_rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the ancesotr acronyms \n",
    "groupA_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                           for f in groupA]\n",
    "groupB_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                           for f in groupB]                           \n",
    "groupC_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                           for f in groupC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003db1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for brain regions\n",
    "\n",
    "# get ancestor of the brain region\n",
    "def get_ancestor_acronym(atlas_df,acronym):\n",
    "    \"\"\"\n",
    "    Get the ancestor acronym for a given acronym\n",
    "    \"\"\"\n",
    "    if acronym in atlas_df['acronym'].values:\n",
    "        ancestor_acronym = atlas_df[atlas_df['acronym'] == acronym]['ancestor_default_acronym'].values[0]\n",
    "    else:\n",
    "        ancestor_acronym = np.nan\n",
    "    return ancestor_acronym\n",
    "\n",
    "# get the number of siblings for a given acronym\n",
    "def get_n_siblings(atlas_df,acronym):\n",
    "    \"\"\"\n",
    "    Get the number of siblings for a given acronym\n",
    "    \"\"\"\n",
    "    if acronym in atlas_df['acronym'].values:\n",
    "        n_siblings = len(atlas_df[atlas_df['parent_acronym'] == atlas_df[atlas_df['acronym'] == acronym]['parent_acronym'].values[0]])\n",
    "    else:\n",
    "        n_siblings = np.nan\n",
    "    return n_siblings\n",
    "\n",
    "# get the number of children for a given acronym\n",
    "def get_n_children(atlas_df,acronym):\n",
    "    \"\"\"\n",
    "    Get the number of children for a given acronym\n",
    "    \"\"\"\n",
    "    if acronym in atlas_df['acronym'].values:\n",
    "        n_children = len(atlas_df[atlas_df['parent_acronym'] == acronym])\n",
    "    else:\n",
    "        n_children = np.nan\n",
    "    return n_children\n",
    "\n",
    "# get the number of siblings of the parent for a given acronym\n",
    "def get_n_siblings_parent(atlas_df,acronym):\n",
    "    \"\"\"\n",
    "    Get the number of siblings of the parent for a given acronym\n",
    "    \"\"\"\n",
    "    if acronym in atlas_df['acronym'].values:\n",
    "        parent_acronym = atlas_df[atlas_df['acronym'] == acronym]['parent_acronym'].values[0]\n",
    "        try:\n",
    "            grandparent_acronym = atlas_df[atlas_df['acronym'] == parent_acronym]['parent_acronym'].values[0]\n",
    "            n_siblings_parent = len(atlas_df[atlas_df['parent_acronym'] == grandparent_acronym])\n",
    "        except:\n",
    "            n_siblings_parent = np.nan\n",
    "    else:\n",
    "        n_siblings_parent = np.nan\n",
    "    return n_siblings_parent\n",
    "\n",
    "# get the depth of the brain regions\n",
    "def get_depth(atlas_df,acronym):\n",
    "    \"\"\"\n",
    "    Get the depth of the brain region for a given acronym\n",
    "    \"\"\"\n",
    "    if acronym in atlas_df['acronym'].values:\n",
    "        depth = atlas_df[atlas_df['acronym'] == acronym]['depth'].values[0]\n",
    "    else:\n",
    "        depth = np.nan\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0baea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the acronyms that are unique to each method\n",
    "brain_regions_category = [groupA,groupB,groupC]\n",
    "brain_regions_category_name = ['groupA','groupB','groupC']\n",
    "\n",
    "for bidx,brain_regions in enumerate(brain_regions_category):\n",
    "    brain_regions = np.array(list(brain_regions))\n",
    "    ancestor_acronyms = [get_ancestor_acronym(atlas_df,acronym) for acronym in brain_regions]\n",
    "    n_siblings_list = [get_n_siblings(atlas_df,acronym) for acronym in brain_regions]\n",
    "    n_children_list = [get_n_children(atlas_df,acronym) for acronym in brain_regions]\n",
    "    n_siblings_parent_list = [get_n_siblings_parent(atlas_df,acronym) for acronym in brain_regions]\n",
    "    depth_list = [get_depth(atlas_df,acronym) for acronym in brain_regions]\n",
    "    # create a dataframe to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'ancestor_acronym': ancestor_acronyms,\n",
    "        'n_siblings': n_siblings_list,\n",
    "        'n_children': n_children_list,\n",
    "        'n_siblings_parent': n_siblings_parent_list,\n",
    "        'depth': depth_list,\n",
    "    },index = brain_regions)\n",
    "    metrics_df['category'] = brain_regions_category_name[bidx]\n",
    "\n",
    "    # merge the metrics_df from the iterations to one\n",
    "    if bidx == 0:\n",
    "        all_metrics_df = metrics_df.copy()\n",
    "    else:\n",
    "        all_metrics_df = pd.concat([all_metrics_df,metrics_df],axis = 0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9661473",
   "metadata": {},
   "source": [
    "### Figure D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestor_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the actual counts as a stacked barplot of ancestor acronyms for each category stored in all_metrics_df ancestor_acronym column\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate counts of ancestor acronyms for each category\n",
    "ancestor_counts = all_metrics_df.groupby(['category', 'ancestor_acronym']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the data to prepare for stacking\n",
    "ancestor_counts_pivot = ancestor_counts.pivot(index='category', columns='ancestor_acronym', values='count').fillna(0)\n",
    "\n",
    "# Reorder the index to match the desired order\n",
    "ancestor_counts_pivot = ancestor_counts_pivot.reindex(['groupA', 'groupB', 'groupC'])\n",
    "\n",
    "# Create a stacked barplot\n",
    "fig = ancestor_counts_pivot.plot(kind='bar', stacked=True, figsize=(2, 2), colormap='tab20',linewidth = 0.5, edgecolor='black')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Ancestor Acronym', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.xticks([0, 1, 2], [\"A\",\"B\",\"C\"], rotation=0)\n",
    "plt.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"),bbox_inches = 'tight', dpi=300)\n",
    "plt.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"),bbox_inches = 'tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683ba32",
   "metadata": {},
   "source": [
    "### Figure E to H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for all parameters\n",
    "from statannotations.Annotator import Annotator\n",
    "pairs = [(brain_regions_category_name[0],brain_regions_category_name[1]),\n",
    "        (brain_regions_category_name[0],brain_regions_category_name[2]),\n",
    "        (brain_regions_category_name[1],brain_regions_category_name[2]),]\n",
    " \n",
    "for pidx,param in enumerate(['depth','n_siblings_parent','n_children','n_siblings',]):\n",
    "    pannel_key = ['E','F','G','H'][pidx]\n",
    "    \n",
    "    \n",
    "    fig,axs = plt.subplots(1,1,figsize = (2.5,2))\n",
    "    sns.stripplot(data = all_metrics_df,\n",
    "                y = param,x = 'category',\n",
    "                order = brain_regions_category_name,\\\n",
    "            ax = axs,alpha = 0.3,size = 3)\n",
    "    sns.pointplot(data = all_metrics_df,\n",
    "                y = param,x = 'category',\n",
    "                order = brain_regions_category_name,\n",
    "            ax = axs,\n",
    "    markers=\"o\", markersize=5, linestyle=\"none\",linewidth = 0.5) \n",
    "    axs.set_ylim(0,)\n",
    "    sns.despine()\n",
    "    axs.set_ylabel(['Level','# of parents siblings','# of children','# of siblings'][pidx])\n",
    "    axs.set_xlabel('Group')\n",
    "    axs.set_xticklabels(['A','B','C'],rotation = 0)\n",
    "    \n",
    "    annotator = Annotator(axs, pairs, data = all_metrics_df,\n",
    "                y = param,x = 'category', order=brain_regions_category_name)\n",
    "    annotator.configure(test='t-test_ind', text_format='star', loc='outside',)\n",
    "    annotator.configure(comparisons_correction=\"BH\", correction_format=\"replace\")\n",
    "    annotator.apply_and_annotate()\n",
    "\n",
    "    fig.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"), dpi=300, bbox_inches='tight')\n",
    "    fig.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"), dpi=300, bbox_inches='tight')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905b9d0",
   "metadata": {},
   "source": [
    "## Figure I to M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25202121",
   "metadata": {},
   "source": [
    "Generate a random list of disjoint brain regions to use for statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17d427",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61898265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_disjoint_nodes(atlas_df, num_nodes, random_state):\n",
    "    \"\"\"\n",
    "    Get X random disjoint nodes from a tree dataset.\n",
    "    Args:\n",
    "        atlas_df (pd.DataFrame): The tree dataset with 'id', 'acronym', and 'parent_acronym' columns.\n",
    "        num_nodes (int): Number of disjoint nodes to retrieve.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "    Returns:\n",
    "        list: A list of disjoint node ids.\n",
    "    \"\"\"\n",
    "    # Create a set to track selected nodes and their descendants\n",
    "    selected_nodes = set()\n",
    "    disjoint_nodes = []\n",
    "\n",
    "    # Shuffle the dataset to randomize node selection\n",
    "    shuffled_nodes = atlas_df.sample(frac=1, random_state=random_state).to_dict('records')\n",
    "\n",
    "    for node in shuffled_nodes:\n",
    "        # Check if the node or its ancestors/descendants are already selected\n",
    "        current_node = node['acronym']\n",
    "        is_disjoint = True\n",
    "\n",
    "        # Check ancestors\n",
    "        while current_node in atlas_df['acronym'].values:\n",
    "            if current_node in selected_nodes:\n",
    "                is_disjoint = False\n",
    "                break\n",
    "            current_node = atlas_df.loc[atlas_df['acronym'] == current_node, 'parent_acronym'].values[0]\n",
    "\n",
    "        # Check descendants\n",
    "        if is_disjoint:\n",
    "            descendants = atlas_df.loc[atlas_df['parent_acronym'] == node['acronym'], 'acronym'].values\n",
    "            if any(descendant in selected_nodes for descendant in descendants):\n",
    "                is_disjoint = False\n",
    "\n",
    "        # Add the node if it is disjoint\n",
    "        if is_disjoint:\n",
    "            disjoint_nodes.append(node['id'])\n",
    "            selected_nodes.add(node['acronym'])\n",
    "            selected_nodes.update(descendants)\n",
    "            #print(node)\n",
    "        # Stop if we have enough nodes\n",
    "        if len(disjoint_nodes) == num_nodes:\n",
    "            break\n",
    "\n",
    "    # Check if the required number of nodes is met\n",
    "    if len(disjoint_nodes) < num_nodes:\n",
    "        return get_random_disjoint_nodes(atlas_df, num_nodes, random_state + 1001)\n",
    "\n",
    "    return disjoint_nodes\n",
    "\n",
    "# Example usage\n",
    "random_disjoint_nodes = get_random_disjoint_nodes(atlas_df, 5, random_state=4)\n",
    "print(\"Random disjoint node IDs:\", random_disjoint_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sub atlas data frame\n",
    "sub_atlas_df = sub_atlas_df[sub_atlas_df.acronym.isin(opioid_bh_comparison_df.acronym)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c14870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through 1000 iterations to get the disjoint nodes and calculate the probability of the rejection\n",
    "import tqdm\n",
    "for n_nodes in [5,10,20,50,100,200,400][2:]:\n",
    "    if not n_nodes == 10:\n",
    "        if os.path.exists(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'random_disjoint_nodes_{n_nodes}.npy')):\n",
    "            print(f'random_disjoint_nodes_{n_nodes} already exists')\n",
    "            #continue\n",
    "    list_nodes = []\n",
    "    for i in tqdm.tqdm(range(1000)):\n",
    "        random_disjoint_nodes = get_random_disjoint_nodes(sub_atlas_df, n_nodes,random_state = i)\n",
    "        # store the random_disjoint_nodes\n",
    "        list_nodes.append(random_disjoint_nodes)\n",
    "    # convert the list_nodes to a np array\n",
    "    list_nodes = np.array(list_nodes)\n",
    "    # write the list_nodes to a npy file\n",
    "    np.save(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'random_disjoint_nodes_{n_nodes}.npy'),list_nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the leaf nodes, leaf nodes can be defined by rows that have an id but doesnt appear in parent_id column\n",
    "leaf_nodes = sub_atlas_df[~sub_atlas_df['acronym'].isin(sub_atlas_df['parent_acronym'])].reset_index()['id'].values\n",
    "# write the list_nodes to a npy file\n",
    "np.save(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'random_disjoint_nodes_{len(leaf_nodes)}.npy'),leaf_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_by_category(opioid_bh_comparison_df,curated_idx):\n",
    "    # calculate the metrics for sets of brain regions in the brain_regions_category\n",
    "    # Prepare data for Venn diagram\n",
    "    treebh_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['TreeBH_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "    flatbh_fishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "    flatbh_nonfishers_rejected = set(opioid_bh_comparison_df[(opioid_bh_comparison_df['flatbh_non-Fishers_rejected'] == True)&(opioid_bh_comparison_df.acronym.isin(curated_acronyms))].acronym.values)\n",
    "\n",
    "    # find the common in treebh_rejected, flatbh_fishers_rejected, flatbh_nonfishers_rejected\n",
    "    groupA = treebh_rejected & flatbh_fishers_rejected & flatbh_nonfishers_rejected\n",
    "\n",
    "    # find the common in treebh_rejected and flatbh_fishers_rejected but not in flatbh_nonfishers_rejected\n",
    "    groupB = (treebh_rejected & flatbh_fishers_rejected) - flatbh_nonfishers_rejected\n",
    "\n",
    "    # find only in flatbh_fishers_rejected but not in treebh_rejected and not in flatbh_nonfishers_rejected\n",
    "    groupC = (flatbh_fishers_rejected - treebh_rejected) - flatbh_nonfishers_rejected\n",
    "\n",
    "\n",
    "    # get the ancesotr acronyms \n",
    "    groupA_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                            for f in groupA]\n",
    "    groupB_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                            for f in groupB]                           \n",
    "    groupC_ancestor = [np.array(ancestor_curated_acronyms)[np.where(np.array(curated_acronyms) == f)][0]\\\n",
    "                            for f in groupC]\n",
    "\n",
    "    brain_regions_category = [groupA,groupB,groupC]\n",
    "    brain_regions_category_name = ['groupA','groupB','groupC']\n",
    "\n",
    "    for bidx,brain_regions in enumerate(brain_regions_category):\n",
    "        brain_regions = np.array(list(brain_regions))\n",
    "        ancestor_acronyms = [get_ancestor_acronym(atlas_df,acronym) for acronym in brain_regions]\n",
    "        n_siblings_list = [get_n_siblings(atlas_df,acronym) for acronym in brain_regions]\n",
    "        n_children_list = [get_n_children(atlas_df,acronym) for acronym in brain_regions]\n",
    "        n_siblings_parent_list = [get_n_siblings_parent(atlas_df,acronym) for acronym in brain_regions]\n",
    "        depth_list = [get_depth(atlas_df,acronym) for acronym in brain_regions]\n",
    "        # create a dataframe to store the metrics\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'ancestor_acronym': ancestor_acronyms,\n",
    "            'n_siblings': n_siblings_list,\n",
    "            'n_children': n_children_list,\n",
    "            'n_siblings_parent': n_siblings_parent_list,\n",
    "            'depth': depth_list,\n",
    "        },index = brain_regions)\n",
    "        metrics_df['category'] = brain_regions_category_name[bidx]\n",
    "\n",
    "        # merge the metrics_df from the iterations to one\n",
    "        if bidx == 0:\n",
    "            all_metrics_df = metrics_df.copy()\n",
    "        else:\n",
    "            all_metrics_df = pd.concat([all_metrics_df,metrics_df],axis = 0)\n",
    "    return all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flatbh_Fishers(opioid_bh_comparison_df,curated_indexes, FDR = 0.01):\n",
    "    \"\"\"\n",
    "    Calculate the flat BH Fisher's method for the given dataframe and curated indexes.\n",
    "    \n",
    "    Args:\n",
    "        opioid_bh_comparison_df (pd.DataFrame): The dataframe containing p-values and other information.\n",
    "        curated_indexes (list): List of curated indexes to filter the dataframe.\n",
    "        FDR (float): False Discovery Rate threshold for multiple testing correction.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with flat BH Fisher's results.\n",
    "    \"\"\"\n",
    "    # Get the p-values for the curated indexes\n",
    "    fishers_pvals = opioid_bh_comparison_df.loc[curated_indexes,'p.val']\n",
    "    \n",
    "    # Perform multiple testing correction using FDR\n",
    "    multiple_testing_results = multitests.multipletests(fishers_pvals, alpha=FDR, method='fdr_bh')\n",
    "    \n",
    "    # Add results to the dataframe\n",
    "    opioid_bh_comparison_df.loc[curated_indexes,'flatbh_Fishers_rejected'] = multiple_testing_results[0]\n",
    "    opioid_bh_comparison_df.loc[curated_indexes,'flatbh_Fishers_p_val'] = multiple_testing_results[1]\n",
    "    \n",
    "    return opioid_bh_comparison_df\n",
    "\n",
    "def calculate_nonflatbh_Fishers(opioid_bh_comparison_df,curated_indexes, FDR = 0.01):\n",
    "    \"\"\"\n",
    "    Calculate the non-flat BH Fisher's method for the given dataframe and curated indexes.\n",
    "    \n",
    "    Args:\n",
    "        opioid_bh_comparison_df (pd.DataFrame): The dataframe containing p-values and other information.\n",
    "        curated_indexes (list): List of curated indexes to filter the dataframe.\n",
    "        FDR (float): False Discovery Rate threshold for multiple testing correction.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with non-flat BH Fisher's results.\n",
    "    \"\"\"\n",
    "    # Get the p-values for the curated indexes\n",
    "    nonfishers_pvals = opioid_bh_comparison_df.loc[curated_indexes,'non-Fishers_p_val']\n",
    "    \n",
    "    # Perform multiple testing correction using FDR\n",
    "    multiple_testing_results = multitests.multipletests(nonfishers_pvals, alpha=FDR, method='fdr_bh')\n",
    "    \n",
    "    # Add results to the dataframe\n",
    "    opioid_bh_comparison_df.loc[curated_indexes,'flatbh_non-Fishers_rejected'] = multiple_testing_results[0]\n",
    "    opioid_bh_comparison_df.loc[curated_indexes,'flatbh_non-Fishers_p_val'] = multiple_testing_results[1]\n",
    "    \n",
    "    return opioid_bh_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc5fd5",
   "metadata": {},
   "source": [
    "Loop through all n_nodes brain regions list, first collect metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "opioid_bh_comparison_df = pd.read_csv(os.path.join(analysis_resultpath, f\"{figure_key}_opioid_bh_comparison_df.csv\"), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the comparison_df\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.set_index('acronym').join(atlas_df.set_index('acronym')[['id','parent_id']]).reset_index()\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.iloc[1:,]\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.set_index('id')\n",
    "# update the comparison_df with the pvalues from the opioid_stat_df\n",
    "opioid_bh_comparison_df = opioid_bh_comparison_df.join(opioid_stat_df.set_index('id')['pvalue']).rename(columns = {'pvalue':'non-Fishers_p_val'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_nodes in [5,10,20,50,100,200,400] + [len(leaf_nodes)]:\n",
    "    print(\"processing n_nodes = \",n_nodes)   \n",
    "    list_nodes = np.load(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'random_disjoint_nodes_{n_nodes}.npy'))\n",
    "    if n_nodes == len(leaf_nodes):\n",
    "        list_nodes = [list_nodes]\n",
    "\n",
    "    discovery_date_list = []\n",
    "    metrics_list = []\n",
    "    combined_metrics_df = pd.DataFrame()\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    for list_node in tqdm(list_nodes):\n",
    "        opioid_bh_comparison_df = calculate_flatbh_Fishers(opioid_bh_comparison_df, list_node, FDR=FDR)\n",
    "        opioid_bh_comparison_df = calculate_nonflatbh_Fishers(opioid_bh_comparison_df, list_node, FDR=FDR)\n",
    "\n",
    "        tdiscovery_rate = np.sum(opioid_bh_comparison_df.loc[list_node, ['TreeBH_rejected', 'flatbh_Fishers_rejected', 'flatbh_non-Fishers_rejected']] == True, axis=0).values / n_nodes\n",
    "        discovery_date_list.append(tdiscovery_rate)\n",
    "\n",
    "        all_metrics_df = calculate_metrics_by_category(opioid_bh_comparison_df, list_node)\n",
    "        all_metrics_df = all_metrics_df[['n_siblings','n_children','n_siblings_parent','depth','category']].groupby('category').mean().reset_index()\n",
    "            \n",
    "        combined_metrics_df = pd.concat([combined_metrics_df, all_metrics_df], axis=0)\n",
    "\n",
    "    discovery_date_list = np.array(discovery_date_list)\n",
    "    discovery_date_list = pd.DataFrame(discovery_date_list, columns=['TreeBH', 'flatbh_Fishers', 'flatbh_non-Fishers'])\n",
    "    discovery_date_list.to_csv(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results', f'discovery_rate_{n_nodes}.csv'), index=False)\n",
    "\n",
    "    combined_metrics_df.to_csv(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results', f'all_metrics_{n_nodes}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82233d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,n_nodes in enumerate([5,10,20,50,100,200,400] + [len(leaf_nodes)]):   \n",
    "    combined_metrics_df = pd.read_csv(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'all_metrics_{n_nodes}.csv'), index_col = False)\n",
    "    combined_metrics_df['n_nodes'] = n_nodes\n",
    "    if idx == 0:\n",
    "        sum_combined_metrics_df = combined_metrics_df\n",
    "    else:\n",
    "        sum_combined_metrics_df = pd.concat([sum_combined_metrics_df,combined_metrics_df],axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through variables\n",
    "for pidx,var in enumerate(['depth','n_siblings_parent','n_children','n_siblings',]):\n",
    "    pannel_key = ['J','K','L','M'][pidx]\n",
    "    g = sns.catplot(data = sum_combined_metrics_df.dropna(),\n",
    "                    x = 'n_nodes',y = var,hue = 'category',native_scale=True,\n",
    "                    kind = 'point',errorbar = 'se',height = 3.2,palette = 'Set2',markersize = 5)\n",
    "    # set the y axis to start from 0\n",
    "    g.set(ylim=(0, None))\n",
    "    plt.ylabel(['Level','# of parents siblings','# of children','# of siblings'][pidx])\n",
    "    plt.xlabel('Number of nodes')\n",
    "    #plt.xticks([5,10,20,50,100,200,400] + [len(leaf_nodes)],\\\n",
    "    #    ['5','10','20','50','100','200','400'] + [f'{len(leaf_nodes)}\\n(leaf nodes)'])\n",
    "    g.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"), dpi=300, bbox_inches='tight')\n",
    "    g.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"), dpi=300, bbox_inches='tight')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef9a28",
   "metadata": {},
   "source": [
    "### Figure I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pannel_key = 'I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,n_nodes in enumerate([5,10,20,50,100,200,400] + [len(leaf_nodes)]):   \n",
    "    discovery_date_list = pd.read_csv(os.path.join(r\"G:\\My Drive\\Opioid_whole_brain_manuscript\\TreeBH comparison\",'results',f'discovery_rate_{n_nodes}.csv'), index_col = False)\n",
    "    discovery_date_list['n_nodes'] = n_nodes\n",
    "    if idx == 0:\n",
    "        sum_discovery_date_list = discovery_date_list\n",
    "    else:\n",
    "        sum_discovery_date_list = pd.concat([sum_discovery_date_list,discovery_date_list],axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_discovery_date_list = sum_discovery_date_list.set_index('n_nodes').stack().reset_index().rename(columns = {'level_1':'Method','n_nodes':'n_nodes',0:'proportion of discovery'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data = sum_discovery_date_list,x = 'n_nodes',y = 'proportion of discovery',\\\n",
    "            hue = 'Method',kind = 'point',errorbar = 'se',height = 3.2,native_scale=True,markersize = 5)\n",
    "            \n",
    "plt.ylim(0,0.5)\n",
    "plt.xlabel('Number of nodes')\n",
    "g.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.png\"), dpi=300, bbox_inches='tight')\n",
    "g.savefig(os.path.join(analysis_figurepath, f\"{figure_key}{pannel_key}.pdf\"), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16faa9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
